t2u:
  codebook_size: 128
  transformer:
    d_model: 256
    nhead: 4
    layer: 2
    dim_feedforward: [256, 256]
    dropout: 0.2
  tacotron2:
    symbols_embedding_dim: 256
    mask_padding: True

    # Encoder parameters
    encoder_kernel_size: 5
    encoder_n_convolutions: 3
    encoder_embedding_dim: 256

    # Decoder parameters
    decoder_rnn_dim: 512
    prenet_dim: 256
    max_decoder_ratio: 10
    gate_threshold: 0.5
    p_attention_dropout: 0.1
    p_decoder_dropout: 0.1

    # Attention parameters
    attention_rnn_dim: 512
    attention_dim: 128

    # Location Layer parameters
    attention_location_n_filters: 32
    attention_location_kernel_size: 31

    d_unit: 256

u2s:
  model_cards: "evaluation/_exp1/model.json"
  model_name: "u2s-zhkofrdees-hubert_large_ll60k-24-512c"
  transformer:
    encoder_layer: 4
    encoder_head: 2
    encoder_hidden: 256
    decoder_layer: 6
    decoder_head: 2
    decoder_hidden: 256
    conv_filter_size: 1024
    conv_kernel_size: [9, 1]
    encoder_dropout: 0.2
    decoder_dropout: 0.2

  variance_predictor:
    filter_size: 256
    kernel_size: 3
    dropout: 0.5

  variance_embedding:
    pitch_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the pitch values are not normalized during preprocessing
    energy_quantization: "linear" # support 'linear' or 'log', 'log' is allowed only if the energy values are not normalized during preprocessing
    n_bins: 256

  pitch:
      feature: "phoneme_level" # support 'phoneme_level' or 'frame_level'
      normalization: True
  energy:
      feature: "phoneme_level" # support 'phoneme_level' or 'frame_level'
      normalization: True

  multi_speaker: True
  multi_lingual: True

  max_seq_len: 1500

  speaker_emb: dvec

  vocoder:
    model: "HifiGAN"
    speaker: "universal" # support  'LJSpeech', 'universal'
